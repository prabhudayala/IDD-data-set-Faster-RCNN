{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall plan of approach\n",
    "<br>\n",
    "<b>\n",
    "<li>1. Collecting data from xml annotations</li>\n",
    "<li>2. Creating files for train and validation</li>\n",
    "<li>3. Train using Faster RCNN model</li>\n",
    "<li>4. Test and calculate MAP</li>\n",
    "<br></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`In this notebook we will cover point 1 and 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import xmltodict\n",
    "import json\n",
    "import os\n",
    "from shutil import copy\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read train txt and parse xml and add all information to list.\n",
    "# here if there are 3 objects in a image then there will be 3 records. with same imagename but different object\n",
    "train_txt_file = open('train.txt','r')\n",
    "all_train_list=[]\n",
    "for i in train_txt_file.readlines():\n",
    "    if(i.strip()[-2:]=='_r'):\n",
    "        pass\n",
    "    else:\n",
    "        with open('Annotations/'+i.strip()+'.xml') as fd:\n",
    "            doc = xmltodict.parse(fd.read())\n",
    "            json1 = json.dumps(doc)\n",
    "            dictionary = json.loads(json1)\n",
    "            if(str(type(dictionary['annotation']['object'])) ==\"<class 'list'>\"):\n",
    "                for i in range(len(dictionary['annotation']['object'])):\n",
    "                    temp_list=[dictionary['annotation']['filename'],dictionary['annotation']['folder'],\n",
    "                               dictionary['annotation']['size']['width'],dictionary['annotation']['size']['height'],\n",
    "                               dictionary['annotation']['object'][i]['name'],\n",
    "                               dictionary['annotation']['object'][i]['bndbox']['xmin'],\n",
    "                               dictionary['annotation']['object'][i]['bndbox']['ymin'],\n",
    "                               dictionary['annotation']['object'][i]['bndbox']['xmax'],\n",
    "                               dictionary['annotation']['object'][i]['bndbox']['ymax']\n",
    "                              ]\n",
    "                    #print(temp_list)\n",
    "                    all_train_list.append(temp_list)\n",
    "            elif(str(type(dictionary['annotation']['object'])) ==\"<class 'dict'>\"):\n",
    "                temp_list=[dictionary['annotation']['filename'],dictionary['annotation']['folder'],\n",
    "                               dictionary['annotation']['size']['width'],dictionary['annotation']['size']['height'],\n",
    "                               dictionary['annotation']['object']['name'],dictionary['annotation']['object']['bndbox']['xmin'],\n",
    "                               dictionary['annotation']['object']['bndbox']['ymin'],\n",
    "                               dictionary['annotation']['object']['bndbox']['xmax'],\n",
    "                               dictionary['annotation']['object']['bndbox']['ymax']]\n",
    "                #print(temp_list)\n",
    "                all_train_list.append(temp_list)\n",
    "            else:\n",
    "                print(type(dictionary['annotation']['object']))\n",
    "                print('Take a look at xml file namend: ',i)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = pd.DataFrame(all_train_list,columns=['filename','folder','width','height','class','xmin','ymin','xmax','ymax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have observed that the folder names mentioned in the xml so i have created separate logic to correct it `Cell 4-10`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Moved all sub directories of given folders(frontFar, frontNear, rearNear, sideLeft, sideLeft, highquality_16k) to a newly created folder new</li>\n",
    "<li>Based on folder names if all subdirectories separated them to different list</li>\n",
    "<li>Sorted those newly created list by descending order of len</li>\n",
    "<li>Based on given folder name in XML, seached corresponding list.</li>\n",
    "<li>Created fully qualified path from root folder and tested if they are available or not.</li>\n",
    "<li>Got perfect results where all files were available.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_folders_all=os.listdir('JPEGImages/all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_far=[]\n",
    "front_near=[]\n",
    "rear_near=[]\n",
    "side_left=[]\n",
    "side_right=[]\n",
    "others=[]\n",
    "part=[]\n",
    "\n",
    "for i in list_of_folders_all:\n",
    "    if 'frontFar' in i:\n",
    "        front_far.append(i)\n",
    "    elif 'frontNear' in i:\n",
    "        front_near.append(i)\n",
    "    elif 'rearNear' in i:\n",
    "        rear_near.append(i)\n",
    "    elif 'sideLeft' in i:\n",
    "        side_left.append(i)\n",
    "    elif 'sideRight' in i:\n",
    "        side_right.append(i)\n",
    "    elif 'part' in i:\n",
    "        part.append(i)\n",
    "    else:\n",
    "        others.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_far.sort(key=lambda x: len(x), reverse = True)\n",
    "front_near.sort(key=lambda x: len(x), reverse = True)\n",
    "rear_near.sort(key=lambda x: len(x), reverse = True)\n",
    "side_left.sort(key=lambda x: len(x), reverse = True)\n",
    "side_right.sort(key=lambda x: len(x), reverse = True)\n",
    "part.sort(key=lambda x: len(x), reverse = True)\n",
    "others.sort(key=lambda x: len(x), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_to_collect_actual_folder(s):\n",
    "    if 'frontFar' in s:\n",
    "        for i in front_far:\n",
    "            if i in s:\n",
    "                return i\n",
    "    elif 'frontNear' in s:\n",
    "        for i in front_near:\n",
    "            if i in s:\n",
    "                return i\n",
    "    elif 'rearNear' in s:\n",
    "        for i in rear_near:\n",
    "            if i in s:\n",
    "                return i\n",
    "    elif 'sideLeft' in s:\n",
    "        for i in side_left:\n",
    "            if i in s:\n",
    "                return i\n",
    "    elif 'sideRight' in s:\n",
    "        for i in side_right:\n",
    "            if i in s:\n",
    "                return i\n",
    "    elif 'part' in s:\n",
    "        for i in part:\n",
    "            if i in s:\n",
    "                return i\n",
    "    else:\n",
    "        for i in others:\n",
    "            if i in s:\n",
    "                return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['folder'] =  train_data_df.folder.apply(method_to_collect_actual_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['filly_qualified_path'] = 'JPEGImages/all/'+train_data_df.folder+'/'+train_data_df.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "328185\n"
     ]
    }
   ],
   "source": [
    "list_to_be_corrected =[]\n",
    "count=0\n",
    "count1=0\n",
    "for i,j in enumerate(train_data_df['filly_qualified_path']):\n",
    "    try:\n",
    "        x = open(j)\n",
    "        count1+=1\n",
    "    except:\n",
    "        count+=1\n",
    "        list_to_be_corrected.append(j)\n",
    "print(count)\n",
    "print(count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`All files are available. Thats good news.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets repeat the same for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read validation txt and parse xml and add all information to list.\n",
    "# here if there are 3 objects in a image then there will be 3 records. with same imagename but different object\n",
    "validation_txt_file = open('val.txt','r')\n",
    "all_validation_list=[]\n",
    "for i in validation_txt_file.readlines():\n",
    "    if(i.strip()[-2:]=='_r'):\n",
    "        pass\n",
    "    else:\n",
    "        with open('Annotations/'+i.strip()+'.xml') as fd:\n",
    "            doc = xmltodict.parse(fd.read())\n",
    "            json1 = json.dumps(doc)\n",
    "            dictionary = json.loads(json1)\n",
    "            if(str(type(dictionary['annotation']['object'])) ==\"<class 'list'>\"):\n",
    "                for i in range(len(dictionary['annotation']['object'])):\n",
    "                    temp_list=[dictionary['annotation']['filename'],dictionary['annotation']['folder'],\n",
    "                               dictionary['annotation']['size']['width'],dictionary['annotation']['size']['height'],\n",
    "                               dictionary['annotation']['object'][i]['name'],\n",
    "                               dictionary['annotation']['object'][i]['bndbox']['xmin'],\n",
    "                               dictionary['annotation']['object'][i]['bndbox']['ymin'],\n",
    "                               dictionary['annotation']['object'][i]['bndbox']['xmax'],\n",
    "                               dictionary['annotation']['object'][i]['bndbox']['ymax']\n",
    "                              ]\n",
    "                    #print(temp_list)\n",
    "                    all_validation_list.append(temp_list)\n",
    "            elif(str(type(dictionary['annotation']['object'])) ==\"<class 'dict'>\"):\n",
    "                temp_list=[dictionary['annotation']['filename'],dictionary['annotation']['folder'],\n",
    "                               dictionary['annotation']['size']['width'],dictionary['annotation']['size']['height'],\n",
    "                               dictionary['annotation']['object']['name'],dictionary['annotation']['object']['bndbox']['xmin'],\n",
    "                               dictionary['annotation']['object']['bndbox']['ymin'],\n",
    "                               dictionary['annotation']['object']['bndbox']['xmax'],\n",
    "                               dictionary['annotation']['object']['bndbox']['ymax']]\n",
    "                #print(temp_list)\n",
    "                all_validation_list.append(temp_list)\n",
    "            else:\n",
    "                print(type(dictionary['annotation']['object']))\n",
    "                print('Take a look at xml file namend: ',i)\n",
    "            \n",
    "\n",
    "validation_data_df = pd.DataFrame(all_validation_list,columns=['filename','folder','width','height','class','xmin','ymin','xmax','ymax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_df['folder'] =  validation_data_df.folder.apply(method_to_collect_actual_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_df['filly_qualified_path'] = 'JPEGImages/all/'+validation_data_df.folder+'/'+validation_data_df.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "110440\n"
     ]
    }
   ],
   "source": [
    "list_to_be_corrected =[]\n",
    "count=0\n",
    "count1=0\n",
    "for i,j in enumerate(validation_data_df['filly_qualified_path']):\n",
    "    try:\n",
    "        x = open(j)\n",
    "        count1+=1\n",
    "    except:\n",
    "        count+=1\n",
    "        list_to_be_corrected.append(j)\n",
    "print(count)\n",
    "print(count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_df.to_csv('validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating formatted data for RCNN model\n",
    "<br>\n",
    "<li>We will create data in format <b>['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'class']</b></li>\n",
    "<li>For each object there will be one entry. In other words if an image have multiple objects, then there will be multiple records for the same image. </li>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328185, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>folder</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>filly_qualified_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006780.jpg</td>\n",
       "      <td>BLR-2018-03-22_17-39-26_2_frontFar</td>\n",
       "      <td>1280</td>\n",
       "      <td>964</td>\n",
       "      <td>truck</td>\n",
       "      <td>586</td>\n",
       "      <td>494</td>\n",
       "      <td>638</td>\n",
       "      <td>551</td>\n",
       "      <td>JPEGImages/all/BLR-2018-03-22_17-39-26_2_front...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0006780.jpg</td>\n",
       "      <td>BLR-2018-03-22_17-39-26_2_frontFar</td>\n",
       "      <td>1280</td>\n",
       "      <td>964</td>\n",
       "      <td>vehicle fallback</td>\n",
       "      <td>470</td>\n",
       "      <td>483</td>\n",
       "      <td>595</td>\n",
       "      <td>613</td>\n",
       "      <td>JPEGImages/all/BLR-2018-03-22_17-39-26_2_front...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0006780.jpg</td>\n",
       "      <td>BLR-2018-03-22_17-39-26_2_frontFar</td>\n",
       "      <td>1280</td>\n",
       "      <td>964</td>\n",
       "      <td>car</td>\n",
       "      <td>638</td>\n",
       "      <td>471</td>\n",
       "      <td>726</td>\n",
       "      <td>537</td>\n",
       "      <td>JPEGImages/all/BLR-2018-03-22_17-39-26_2_front...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006780.jpg</td>\n",
       "      <td>BLR-2018-03-22_17-39-26_2_frontFar</td>\n",
       "      <td>1280</td>\n",
       "      <td>964</td>\n",
       "      <td>motorcycle</td>\n",
       "      <td>836</td>\n",
       "      <td>523</td>\n",
       "      <td>916</td>\n",
       "      <td>585</td>\n",
       "      <td>JPEGImages/all/BLR-2018-03-22_17-39-26_2_front...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0006780.jpg</td>\n",
       "      <td>BLR-2018-03-22_17-39-26_2_frontFar</td>\n",
       "      <td>1280</td>\n",
       "      <td>964</td>\n",
       "      <td>rider</td>\n",
       "      <td>837</td>\n",
       "      <td>518</td>\n",
       "      <td>859</td>\n",
       "      <td>550</td>\n",
       "      <td>JPEGImages/all/BLR-2018-03-22_17-39-26_2_front...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                              folder  width  height  \\\n",
       "0  0006780.jpg  BLR-2018-03-22_17-39-26_2_frontFar   1280     964   \n",
       "1  0006780.jpg  BLR-2018-03-22_17-39-26_2_frontFar   1280     964   \n",
       "2  0006780.jpg  BLR-2018-03-22_17-39-26_2_frontFar   1280     964   \n",
       "3  0006780.jpg  BLR-2018-03-22_17-39-26_2_frontFar   1280     964   \n",
       "4  0006780.jpg  BLR-2018-03-22_17-39-26_2_frontFar   1280     964   \n",
       "\n",
       "              class  xmin  ymin  xmax  ymax  \\\n",
       "0             truck   586   494   638   551   \n",
       "1  vehicle fallback   470   483   595   613   \n",
       "2               car   638   471   726   537   \n",
       "3        motorcycle   836   523   916   585   \n",
       "4             rider   837   518   859   550   \n",
       "\n",
       "                                filly_qualified_path  \n",
       "0  JPEGImages/all/BLR-2018-03-22_17-39-26_2_front...  \n",
       "1  JPEGImages/all/BLR-2018-03-22_17-39-26_2_front...  \n",
       "2  JPEGImages/all/BLR-2018-03-22_17-39-26_2_front...  \n",
       "3  JPEGImages/all/BLR-2018-03-22_17-39-26_2_front...  \n",
       "4  JPEGImages/all/BLR-2018-03-22_17-39-26_2_front...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4397"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.filename.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21458"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.filly_qualified_path.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`There are many images of same name in different directory. So while storing images in different directory i will rename the images and make a list for further reference.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('train')\n",
    "for i in train['class'].unique():\n",
    "    os.mkdir('train/'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy all files to a new directory as train\n",
    "new_file_names = []\n",
    "for i, j in train.iterrows():\n",
    "    dest = j['filly_qualified_path'].split('/')[-2]+j['filename']\n",
    "    new_file_names.append(dest)\n",
    "    copy(j['filly_qualified_path'],'train/'+dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['new_file_name'] = new_file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repeat for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110440, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>folder</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>filly_qualified_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006780.jpg</td>\n",
       "      <td>BLR-2018-04-16_16-14-27_frontFar</td>\n",
       "      <td>1280</td>\n",
       "      <td>964</td>\n",
       "      <td>truck</td>\n",
       "      <td>401</td>\n",
       "      <td>392</td>\n",
       "      <td>619</td>\n",
       "      <td>488</td>\n",
       "      <td>JPEGImages/all/BLR-2018-04-16_16-14-27_frontFa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0006780.jpg</td>\n",
       "      <td>BLR-2018-04-16_16-14-27_frontFar</td>\n",
       "      <td>1280</td>\n",
       "      <td>964</td>\n",
       "      <td>truck</td>\n",
       "      <td>638</td>\n",
       "      <td>381</td>\n",
       "      <td>835</td>\n",
       "      <td>497</td>\n",
       "      <td>JPEGImages/all/BLR-2018-04-16_16-14-27_frontFa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0006780.jpg</td>\n",
       "      <td>BLR-2018-04-16_16-14-27_frontFar</td>\n",
       "      <td>1280</td>\n",
       "      <td>964</td>\n",
       "      <td>truck</td>\n",
       "      <td>733</td>\n",
       "      <td>379</td>\n",
       "      <td>928</td>\n",
       "      <td>493</td>\n",
       "      <td>JPEGImages/all/BLR-2018-04-16_16-14-27_frontFa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006780.jpg</td>\n",
       "      <td>BLR-2018-04-16_16-14-27_frontFar</td>\n",
       "      <td>1280</td>\n",
       "      <td>964</td>\n",
       "      <td>person</td>\n",
       "      <td>1093</td>\n",
       "      <td>486</td>\n",
       "      <td>1172</td>\n",
       "      <td>707</td>\n",
       "      <td>JPEGImages/all/BLR-2018-04-16_16-14-27_frontFa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0006780.jpg</td>\n",
       "      <td>BLR-2018-04-16_16-14-27_frontFar</td>\n",
       "      <td>1280</td>\n",
       "      <td>964</td>\n",
       "      <td>motorcycle</td>\n",
       "      <td>1101</td>\n",
       "      <td>426</td>\n",
       "      <td>1144</td>\n",
       "      <td>463</td>\n",
       "      <td>JPEGImages/all/BLR-2018-04-16_16-14-27_frontFa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                            folder  width  height       class  \\\n",
       "0  0006780.jpg  BLR-2018-04-16_16-14-27_frontFar   1280     964       truck   \n",
       "1  0006780.jpg  BLR-2018-04-16_16-14-27_frontFar   1280     964       truck   \n",
       "2  0006780.jpg  BLR-2018-04-16_16-14-27_frontFar   1280     964       truck   \n",
       "3  0006780.jpg  BLR-2018-04-16_16-14-27_frontFar   1280     964      person   \n",
       "4  0006780.jpg  BLR-2018-04-16_16-14-27_frontFar   1280     964  motorcycle   \n",
       "\n",
       "   xmin  ymin  xmax  ymax                               filly_qualified_path  \n",
       "0   401   392   619   488  JPEGImages/all/BLR-2018-04-16_16-14-27_frontFa...  \n",
       "1   638   381   835   497  JPEGImages/all/BLR-2018-04-16_16-14-27_frontFa...  \n",
       "2   733   379   928   493  JPEGImages/all/BLR-2018-04-16_16-14-27_frontFa...  \n",
       "3  1093   486  1172   707  JPEGImages/all/BLR-2018-04-16_16-14-27_frontFa...  \n",
       "4  1101   426  1144   463  JPEGImages/all/BLR-2018-04-16_16-14-27_frontFa...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = pd.read_csv('validation.csv')\n",
    "validation.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "print(validation.shape)\n",
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('validation')\n",
    "for i in validation['class'].unique():\n",
    "    os.mkdir('validation/'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy all files to a new directory as validation\n",
    "new_file_names = []\n",
    "for i, j in validation.iterrows():\n",
    "    dest = j['filly_qualified_path'].split('/')[-2]+j['filename']\n",
    "    new_file_names.append(dest)\n",
    "    copy(j['filly_qualified_path'],'validation/'+dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['new_file_name'] = new_file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we have new unique filenames. Lets create tain_input and validation_input files.\n",
    "These are the files which will be directly passed to Faster RCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['path'] = \"train/\"+train['new_file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['path'] = \"validation/\"+validation['new_file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "outF = open(\"train_input.txt\", \"w\")\n",
    "for i, j in train.iterrows():\n",
    "    #print(str(j['path'])+','+str(j['xmin'])+','+str(j['ymin'])+','+str(j['xmax'])+','+str(j['ymax'])+','+str(j['class']))\n",
    "    outF.write(str(j['path'])+','+str(j['xmin'])+','+str(j['ymin'])+','+str(j['xmax'])+','+str(j['ymax'])+','+str(j['class']))\n",
    "    outF.write(\"\\n\")\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "outF1 = open(\"validation_input.txt\", \"w\")\n",
    "for i, j in validation.iterrows():\n",
    "    #print(str(j['path'])+','+str(j['xmin'])+','+str(j['ymin'])+','+str(j['xmax'])+','+str(j['ymax'])+','+str(j['class']))\n",
    "    outF1.write(str(j['path'])+','+str(j['xmin'])+','+str(j['ymin'])+','+str(j['xmax'])+','+str(j['ymax'])+','+str(j['class']))\n",
    "    outF1.write(\"\\n\")\n",
    "outF1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two sample records from train_input.txt(input for Fasster RCNN model)\n",
    "<br>train/BLR-2018-03-22_17-39-26_2_frontFar0006780.jpg,586,494,638,551,truck\n",
    "<br>train/BLR-2018-03-22_17-39-26_2_frontFar0006780.jpg,470,483,595,613,vehicle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two sample records from validation_input.txt\n",
    "<br>validation/BLR-2018-04-16_16-14-27_frontFar0006780.jpg,401,392,619,488,truck\n",
    "<br>validation/BLR-2018-04-16_16-14-27_frontFar0006780.jpg,638,381,835,497,truck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`We will start with training now in next notebook`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
